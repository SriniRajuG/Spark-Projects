{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mounting folders from S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Mounting weclouddata/datasets/telecom/CDR\n",
       "/mnt/cdr has been unmounted.\n",
       "The bucket weclouddata/datasets/telecom/CDR was mounted to /mnt/cdr \n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def mountBucket(accesskey, secretkey, bucketName, mountFolder):\n",
    "  ACCESS_KEY_ID = accesskey\n",
    "  SECRET_ACCESS_KEY = secretkey\n",
    "  print (\"Mounting\", bucketName)\n",
    "  try:\n",
    "    # Unmount the data in case it was already mounted.\n",
    "    dbutils.fs.unmount(mountFolder)\n",
    "  except:\n",
    "    # If it fails to unmount it most likely wasn't mounted in the first place\n",
    "    print (\"Directory not unmounted: \", mountFolder )\n",
    "  finally:\n",
    "    # Lastly, mount our bucket.\n",
    "    dbutils.fs.mount(\"s3a://\"+ ACCESS_KEY_ID + \":\" + SECRET_ACCESS_KEY + \"@\" + bucketName, mountFolder)\n",
    "    print (\"The bucket\", bucketName, \"was mounted to\", mountFolder, \"\\n\")\n",
    "\n",
    "# Set AWS programmatic access credentials\n",
    "access_key_id = \"XXXXXXXXXXXXXXXXXXXXXXXXXXXXX\"\n",
    "secret_access_key = \"YYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYY\"\n",
    "\n",
    "# Mount buckets\n",
    "mountBucket(access_key_id, secret_access_key, \"weclouddata/datasets/telecom/CDR\", \"/mnt/cdr\")\n",
    "\n",
    "# mountBucket(access_key_id, secret_access_key, \"weclouddata/datasets/wikipedia\", \"/mnt/wikipedia\")\n",
    "# mountBucket(access_key_id, secret_access_key, \"weclouddata/datasets/entertainment/movie\", \"/mnt/movie\")\n",
    "# mountBucket(access_key_id, secret_access_key, \"weclouddata/datasets/telecom/anonymous_telecom\", \"/mnt/anonymous_telecom\")\n",
    "# mountBucket(access_key_id, secret_access_key, \"weclouddata/datasets/telecom/churn/china_telecom\", \"/mnt/china_telecom_churn\")\n",
    "# mountBucket(access_key_id, secret_access_key, \"weclouddata/datasets/social/twitter\", \"/mnt/twitter\")\n",
    "# mountBucket(access_key_id, secret_access_key, \"weclouddata/datasets/logs/aws_logs\", \"/mnt/aws_logs\")\n",
    "# mountBucket(access_key_id, secret_access_key, \"weclouddata/datasets/random/shakespeare\", \"/mnt/shakespeare\")\n",
    "# mountBucket(access_key_id, secret_access_key, \"weclouddata/datasets/geo\", \"/mnt/geo\")\n",
    "# mountBucket(access_key_id, secret_access_key, \"weclouddata/datasets/telecom/churn/churn_orange_telecom_sample\", \"/mnt/orange\")\n",
    "# mountBucket(access_key_id, secret_access_key, \"weclouddata/datasets/social/stackoverflow\", \"/mnt/stackoverflow\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th></tr></thead><tbody><tr><td>dbfs:/mnt/cdr/cdr_by_grid_december/</td><td>cdr_by_grid_december/</td><td>0</td></tr><tr><td>dbfs:/mnt/cdr/cdr_by_grid_november/</td><td>cdr_by_grid_november/</td><td>0</td></tr><tr><td>dbfs:/mnt/cdr/cdr_grid_to_grid_2013_december_full.zip</td><td>cdr_grid_to_grid_2013_december_full.zip</td><td>48988967347</td></tr><tr><td>dbfs:/mnt/cdr/cdr_grid_to_grid_2013_november_full.zip</td><td>cdr_grid_to_grid_2013_november_full.zip</td><td>51059323347</td></tr><tr><td>dbfs:/mnt/cdr/mi_meteo_legend.csv</td><td>mi_meteo_legend.csv</td><td>2295</td></tr><tr><td>dbfs:/mnt/cdr/milano-grid.zip</td><td>milano-grid.zip</td><td>332144</td></tr><tr><td>dbfs:/mnt/cdr/milano_weather_station.zip</td><td>milano_weather_station.zip</td><td>157313</td></tr><tr><td>dbfs:/mnt/cdr/zip/</td><td>zip/</td><td>0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%fs ls '/mnt/cdr'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing mounted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">dbfs:/mnt/cdr/cdr_by_grid_december/\n",
       "dbfs:/mnt/cdr/cdr_by_grid_november/\n",
       "dbfs:/mnt/cdr/cdr_grid_to_grid_2013_december_full.zip\n",
       "dbfs:/mnt/cdr/cdr_grid_to_grid_2013_november_full.zip\n",
       "dbfs:/mnt/cdr/mi_meteo_legend.csv\n",
       "dbfs:/mnt/cdr/milano-grid.zip\n",
       "dbfs:/mnt/cdr/milano_weather_station.zip\n",
       "dbfs:/mnt/cdr/zip/\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display the CDR folder\n",
    "cdr_files = dbutils.fs.ls(\"/mnt/cdr\")\n",
    "\n",
    "for fileInfo in cdr_files:\n",
    "  print(fileInfo.path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th></tr></thead><tbody><tr><td>dbfs:/mnt/cdr/cdr_by_grid_december/</td><td>cdr_by_grid_december/</td><td>0</td></tr><tr><td>dbfs:/mnt/cdr/cdr_by_grid_november/</td><td>cdr_by_grid_november/</td><td>0</td></tr><tr><td>dbfs:/mnt/cdr/cdr_grid_to_grid_2013_december_full.zip</td><td>cdr_grid_to_grid_2013_december_full.zip</td><td>48988967347</td></tr><tr><td>dbfs:/mnt/cdr/cdr_grid_to_grid_2013_november_full.zip</td><td>cdr_grid_to_grid_2013_november_full.zip</td><td>51059323347</td></tr><tr><td>dbfs:/mnt/cdr/mi_meteo_legend.csv</td><td>mi_meteo_legend.csv</td><td>2295</td></tr><tr><td>dbfs:/mnt/cdr/milano-grid.zip</td><td>milano-grid.zip</td><td>332144</td></tr><tr><td>dbfs:/mnt/cdr/milano_weather_station.zip</td><td>milano_weather_station.zip</td><td>157313</td></tr><tr><td>dbfs:/mnt/cdr/zip/</td><td>zip/</td><td>0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display the CDR folder\n",
    "display( cdr_files )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Session created\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a Spark session and Spark context\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName('Spark tutorial') \\\n",
    "        .getOrCreate()\n",
    "print('Session created')\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manually create spark dataframes\n",
    "\n",
    "https://spark.apache.org/docs/2.1.0/api/python/pyspark.sql.html#pyspark.sql.SparkSession.createDataFrame  \n",
    "https://spark.apache.org/docs/2.1.0/api/python/pyspark.sql.html#pyspark.sql.DataFrame.toDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a simple DF \n",
    "data = [(\"jose\", 1), (\"li\", 2), (\"liz\", 3)]\n",
    "myDf = spark.createDataFrame(data=data, schema=[\"name\", \"age\"])\n",
    "\n",
    "# Create a DF from an RDD\n",
    "rdd = sc.parallelize([(1,2,3),(4,5,6),(7,8,9)])\n",
    "myDf = rdd.toDF([\"a\",\"b\",\"c\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create DF from files\n",
    "\n",
    "https://spark.apache.org/docs/2.1.0/api/python/pyspark.sql.html#pyspark.sql.DataFrameReader\n",
    "\n",
    "There are two ways of using the methods in DataFrameReader. All the **options** for a method like .csv should be chained before using .csv().  \n",
    "It will take more time to create a spark-data-frame (SDF) if the option inferSchema is set to be true. If inferSchema is false, all the columns are read as strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fName = \"/mnt/wikipedia/pageviews/pageviews_by_second.csv\"\n",
    "wikiDF = spark.read.csv(\n",
    "    path=fName, \n",
    "    sep='\\t', \n",
    "    header='true', \n",
    "    inferSchema='false'\n",
    ")\n",
    "wikiDF = (spark.read\n",
    "    .option('sep', '\\t')\n",
    "    .option('header', 'true')\n",
    "    .option('inferSchema', 'false')\n",
    "    .csv(fName)\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use `StructType` and `StructField` to define schema for the DF**  \n",
    "If there are a large no. of columns, create a csv file with the schema specification (colName, dType, nullable) and create a list of StructField objects by reading the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, LongType, FloatType\n",
    "\n",
    "cdrFile = '/mnt/cdr/cdr_by_grid_december/sms-call-internet-mi-2013-12-01.txt'\n",
    "cdrSchema = StructType([\n",
    "    StructField(\"square_id\", IntegerType(), True),\n",
    "    StructField(\"time_interval\", LongType(), True),\n",
    "    StructField(\"country_code\", IntegerType(), True),\n",
    "    StructField(\"sms_in_activity\", FloatType(), True),\n",
    "    StructField(\"sms_out_activity\", FloatType(), True),\n",
    "    StructField(\"call_in_activity\", FloatType(), True),\n",
    "    StructField(\"call_out_activity\", FloatType(), True),\n",
    "    StructField(\"internet_activity\", FloatType(), True)]\n",
    ")\n",
    "cdr = (spark.read\n",
    "    .option(\"header\", \"true\")\n",
    "    .option(\"delimiter\", \"\\t\")\n",
    "    .schema(cdrSchema)\n",
    "    .csv(cdrFile)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read Parquet files**\n",
    "* We do not need to specify the schema - the column names and data types are stored in the parquet files.\n",
    "* Only one job is required to read that schema from the parquet file's metadata.\n",
    "* Unlike the CSV or JSON readers that have to load the entire file and then infer the schema, the parquet reader can \"read\" the schema very quickly because it's reading that schema from the metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wikiParquetFiles = \"/mnt/wikipedia/pageviews/pageviews_by_second.parquet/\"\n",
    "\n",
    "wikiParquet = (spark.read              \n",
    "  .parquet(wikiParquetFiles)  \n",
    ")\n",
    "\n",
    "# Explicitly specify the schema\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, TimestampType\n",
    "wikiSchema = StructType([\n",
    "  StructField(\"timestamp\", TimestampType(), False),\n",
    "  StructField(\"site\", StringType(), False),\n",
    "  StructField(\"requests\", IntegerType(), False)\n",
    "])\n",
    "wikiParquet = (spark.read              \n",
    "  .option(\"delimiter\", \"\\t\")  \n",
    "  .schema(wikiSchema)          # Use the specified schema\n",
    "  .parquet(wikiParquetFiles)   # Creates a DataFrame from Parquet after reading in the file\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Writing a DF to disk**  \n",
    "https://spark.apache.org/docs/2.1.0/api/python/pyspark.sql.html#pyspark.sql.DataFrameWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wikiOut = \"/tmp/pageviews_by_second.csv\"\n",
    "(wikiDF.write                       # Our DataFrameWriter\n",
    "  .option(\"delimiter\", \"\\t\")  \n",
    "  .option(\"header\", \"true\")\n",
    "  .mode(\"overwrite\")               # Replace existing files\n",
    "  .csv(wikiOut)               # Write DataFrame to csv files\n",
    ")\n",
    "\n",
    "wikiOutParquet = \"/tmp/pageviews_by_second.parquet\"\n",
    "(wikiDF.write                       # Our DataFrameWriter\n",
    "  .option(\"delimiter\", \"\\t\")  \n",
    "  .option(\"compression\", \"snappy\")\n",
    "  .mode(\"overwrite\")               # Replace existing files\n",
    "  .parquet(wikiOutParquet)               # Write DataFrame to csv files\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Action operations  \n",
    "DataFrame Actions either return a result or write to disc.\n",
    "\n",
    "* Display the first n rows of the DF\n",
    "* Return a list of first n **Row objects** from a DF\n",
    "* Return the no of records in a DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+---------+-------------+------------+---------------+----------------+----------------+-----------------+-----------------+\n",
       "square_id|time_interval|country_code|sms_in_activity|sms_out_activity|call_in_activity|call_out_activity|internet_activity|\n",
       "+---------+-------------+------------+---------------+----------------+----------------+-----------------+-----------------+\n",
       "        1|1385852400000|          46|           null|            null|            null|             null|      0.026137425|\n",
       "        1|1385853000000|          39|     0.16513683|      0.17639945|     0.030875085|      0.027300464|        13.330858|\n",
       "        1|1385853600000|           0|    0.029087774|     0.027300464|            null|             null|             null|\n",
       "        1|1385853600000|          39|     0.18645109|      0.13658783|     0.054600928|             null|        11.329553|\n",
       "        1|1385854200000|          39|     0.21965227|      0.38112897|      0.08252566|       0.13596356|       13.1661625|\n",
       "+---------+-------------+------------+---------------+----------------+----------------+-----------------+-----------------+\n",
       "only showing top 5 rows\n",
       "\n",
       "[Row(square_id=1, time_interval=1385852400000, country_code=46, sms_in_activity=None, sms_out_activity=None, call_in_activity=None, call_out_activity=None, internet_activity=0.026137424632906914), Row(square_id=1, time_interval=1385853000000, country_code=39, sms_in_activity=0.16513682901859283, sms_out_activity=0.17639945447444916, call_in_activity=0.030875084921717644, call_out_activity=0.027300463989377022, internet_activity=13.33085823059082), Row(square_id=1, time_interval=1385853600000, country_code=0, sms_in_activity=0.029087774455547333, sms_out_activity=0.027300463989377022, call_in_activity=None, call_out_activity=None, internet_activity=None), Row(square_id=1, time_interval=1385853600000, country_code=39, sms_in_activity=0.18645109236240387, sms_out_activity=0.13658782839775085, call_in_activity=0.054600927978754044, call_out_activity=None, internet_activity=11.32955265045166), Row(square_id=1, time_interval=1385854200000, country_code=39, sms_in_activity=0.21965226531028748, sms_out_activity=0.3811289668083191, call_in_activity=0.08252566307783127, call_out_activity=0.1359635591506958, internet_activity=13.166162490844727)]\n",
       "\n",
       "4438330\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the first n rows of the DF\n",
    "cdr.show(5, truncate=True) # columns longer than 20 chars are truncated\n",
    "\n",
    "# Return a list of first n Row objects from a DF\n",
    "rowsList = cdr.take(5)\n",
    "print(rowsList)\n",
    "print()\n",
    "\n",
    "# Return the no of records in a DF\n",
    "nRows = cdr.count()\n",
    "print(nRows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[13]: 1</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Extracting elements of a Row object\n",
    "\n",
    "from pyspark.sql import Row\n",
    "\n",
    "a_row = Row(foo=1, bar=True)\n",
    "a_row.__getattr__(\"foo\")\n",
    "a_row.__getitem__(\"foo\")\n",
    "a_row[\"foo\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformation operations  \n",
    "* Create a new DF with top n Rows\n",
    "* Create a new DF with chosen columns\n",
    "* Create a new DF after dropping a few columns\n",
    "* Create a new DF with distinct rows from original sdf\n",
    "* Create a new DF with rows ordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+---------+-------------+------------+---------------+----------------+----------------+-----------------+-----------------+\n",
       "square_id|time_interval|country_code|sms_in_activity|sms_out_activity|call_in_activity|call_out_activity|internet_activity|\n",
       "+---------+-------------+------------+---------------+----------------+----------------+-----------------+-----------------+\n",
       "        1|1385852400000|          46|           null|            null|            null|             null|      0.026137425|\n",
       "        1|1385853000000|          39|     0.16513683|      0.17639945|     0.030875085|      0.027300464|        13.330858|\n",
       "        1|1385853600000|           0|    0.029087774|     0.027300464|            null|             null|             null|\n",
       "        1|1385853600000|          39|     0.18645109|      0.13658783|     0.054600928|             null|        11.329553|\n",
       "        1|1385854200000|          39|     0.21965227|      0.38112897|      0.08252566|       0.13596356|       13.1661625|\n",
       "+---------+-------------+------------+---------------+----------------+----------------+-----------------+-----------------+\n",
       "\n",
       "+---------+-------------+------------+---------------+----------------+----------------+-----------------+-----------------+\n",
       "square_id|time_interval|country_code|sms_in_activity|sms_out_activity|call_in_activity|call_out_activity|internet_activity|\n",
       "+---------+-------------+------------+---------------+----------------+----------------+-----------------+-----------------+\n",
       "        1|1385852400000|          46|           null|            null|            null|             null|      0.026137425|\n",
       "        1|1385853000000|          39|     0.16513683|      0.17639945|     0.030875085|      0.027300464|        13.330858|\n",
       "        1|1385853600000|           0|    0.029087774|     0.027300464|            null|             null|             null|\n",
       "        1|1385853600000|          39|     0.18645109|      0.13658783|     0.054600928|             null|        11.329553|\n",
       "        1|1385854200000|          39|     0.21965227|      0.38112897|      0.08252566|       0.13596356|       13.1661625|\n",
       "+---------+-------------+------------+---------------+----------------+----------------+-----------------+-----------------+\n",
       "\n",
       "+---------+------------+\n",
       "square_id|country_code|\n",
       "+---------+------------+\n",
       "      100|        1647|\n",
       "     1004|          40|\n",
       "     1007|         355|\n",
       "     1008|         373|\n",
       "     1018|         380|\n",
       "      102|          86|\n",
       "     1033|          33|\n",
       "     1033|         971|\n",
       "     1039|          48|\n",
       "     1047|          63|\n",
       "     1060|           0|\n",
       "     1066|         370|\n",
       "     1074|          48|\n",
       "     1075|          53|\n",
       "     1076|         352|\n",
       "     1088|          31|\n",
       "     1096|          46|\n",
       "     1100|          94|\n",
       "     1128|         216|\n",
       "     1135|        1829|\n",
       "+---------+------------+\n",
       "only showing top 20 rows\n",
       "\n",
       "+---------+------------+\n",
       "square_id|country_code|\n",
       "+---------+------------+\n",
       "      100|        1647|\n",
       "     1004|          40|\n",
       "     1007|         355|\n",
       "     1008|         373|\n",
       "     1018|         380|\n",
       "      102|          86|\n",
       "     1033|          33|\n",
       "     1033|         971|\n",
       "     1039|          48|\n",
       "     1047|          63|\n",
       "     1060|           0|\n",
       "     1066|         370|\n",
       "     1074|          48|\n",
       "     1075|          53|\n",
       "     1076|         352|\n",
       "     1088|          31|\n",
       "     1096|          46|\n",
       "     1100|          94|\n",
       "     1128|         216|\n",
       "     1135|        1829|\n",
       "+---------+------------+\n",
       "only showing top 20 rows\n",
       "\n",
       "+---------+-------------+------------+---------------+----------------+----------------+-----------------+-----------------+\n",
       "square_id|time_interval|country_code|sms_in_activity|sms_out_activity|call_in_activity|call_out_activity|internet_activity|\n",
       "+---------+-------------+------------+---------------+----------------+----------------+-----------------+-----------------+\n",
       "        1|1385869800000|           0|    0.027300464|            null|            null|             null|             null|\n",
       "        1|1385887800000|           0|      0.2493643|            null|            null|             null|             null|\n",
       "        1|1385870400000|           0|    0.027300464|            null|            null|             null|             null|\n",
       "        1|1385856000000|           0|    0.026137425|            null|            null|             null|             null|\n",
       "        1|1385874000000|           0|     0.05227485|            null|            null|             null|             null|\n",
       "        1|1385859600000|           0|    0.027300464|            null|            null|             null|             null|\n",
       "        1|1385875200000|           0|    0.027300464|            null|            null|             null|             null|\n",
       "        1|1385863200000|           0|     0.05343789|            null|            null|      0.027300464|             null|\n",
       "        1|1385875800000|           0|    0.026137425|            null|            null|             null|             null|\n",
       "        1|1385864400000|           0|           null|            null|            null|     0.0017873101|             null|\n",
       "        1|1385876400000|           0|    0.027300464|            null|            null|             null|             null|\n",
       "        1|1385866200000|           0|    0.027300464|            null|            null|       0.05227485|             null|\n",
       "        1|1385877000000|           0|   0.0017873101|            null|            null|             null|             null|\n",
       "        1|1385882400000|           0|      0.4641934|            null|            null|             null|             null|\n",
       "        1|1385883000000|           0|     0.38175324|            null|            null|             null|             null|\n",
       "        1|1385853600000|           0|    0.029087774|     0.027300464|            null|             null|             null|\n",
       "        1|1385883600000|           0|     0.38121447|            null|            null|       0.05584947|             null|\n",
       "        1|1385862600000|           0|    0.029087774|            null|            null|             null|             null|\n",
       "        1|1385884200000|           0|     0.42991468|            null|            null|             null|             null|\n",
       "        1|1385865600000|           0|     0.05227485|            null|            null|             null|             null|\n",
       "+---------+-------------+------------+---------------+----------------+----------------+-----------------+-----------------+\n",
       "only showing top 20 rows\n",
       "\n",
       "+---------+-------------+------------+---------------+----------------+----------------+-----------------+-----------------+\n",
       "square_id|time_interval|country_code|sms_in_activity|sms_out_activity|call_in_activity|call_out_activity|internet_activity|\n",
       "+---------+-------------+------------+---------------+----------------+----------------+-----------------+-----------------+\n",
       "        1|1385869800000|           0|    0.027300464|            null|            null|             null|             null|\n",
       "        1|1385887800000|           0|      0.2493643|            null|            null|             null|             null|\n",
       "        1|1385870400000|           0|    0.027300464|            null|            null|             null|             null|\n",
       "        1|1385856000000|           0|    0.026137425|            null|            null|             null|             null|\n",
       "        1|1385874000000|           0|     0.05227485|            null|            null|             null|             null|\n",
       "        1|1385859600000|           0|    0.027300464|            null|            null|             null|             null|\n",
       "        1|1385875200000|           0|    0.027300464|            null|            null|             null|             null|\n",
       "        1|1385863200000|           0|     0.05343789|            null|            null|      0.027300464|             null|\n",
       "        1|1385875800000|           0|    0.026137425|            null|            null|             null|             null|\n",
       "        1|1385864400000|           0|           null|            null|            null|     0.0017873101|             null|\n",
       "        1|1385876400000|           0|    0.027300464|            null|            null|             null|             null|\n",
       "        1|1385866200000|           0|    0.027300464|            null|            null|       0.05227485|             null|\n",
       "        1|1385877000000|           0|   0.0017873101|            null|            null|             null|             null|\n",
       "        1|1385882400000|           0|      0.4641934|            null|            null|             null|             null|\n",
       "        1|1385883000000|           0|     0.38175324|            null|            null|             null|             null|\n",
       "        1|1385853600000|           0|    0.029087774|     0.027300464|            null|             null|             null|\n",
       "        1|1385883600000|           0|     0.38121447|            null|            null|       0.05584947|             null|\n",
       "        1|1385862600000|           0|    0.029087774|            null|            null|             null|             null|\n",
       "        1|1385884200000|           0|     0.42991468|            null|            null|             null|             null|\n",
       "        1|1385865600000|           0|     0.05227485|            null|            null|             null|             null|\n",
       "+---------+-------------+------------+---------------+----------------+----------------+-----------------+-----------------+\n",
       "only showing top 20 rows\n",
       "\n",
       "+---------+-------------+------------+---------------+----------------+----------------+-----------------+-----------------+\n",
       "square_id|time_interval|country_code|sms_in_activity|sms_out_activity|call_in_activity|call_out_activity|internet_activity|\n",
       "+---------+-------------+------------+---------------+----------------+----------------+-----------------+-----------------+\n",
       "     3564|1385912400000|       97259|      0.5710262|            null|            null|             null|             null|\n",
       "     3462|1385912400000|       97259|      0.2098932|            null|            null|             null|             null|\n",
       "     3464|1385912400000|       97259|     0.19292864|            null|            null|             null|             null|\n",
       "     3663|1385912400000|       97259|     0.24540168|            null|            null|             null|             null|\n",
       "     3563|1385912400000|       97259|       0.752031|            null|            null|             null|             null|\n",
       "     3467|1385912400000|       97259|     0.17073873|            null|            null|             null|             null|\n",
       "     3367|1385912400000|       97259|     0.00790323|            null|            null|             null|             null|\n",
       "     3463|1385912400000|       97259|     0.45257905|            null|            null|             null|             null|\n",
       "     3368|1385912400000|       97259|      0.1628355|            null|            null|             null|             null|\n",
       "     3562|1385912400000|       97259|      0.2631056|            null|            null|             null|             null|\n",
       "     3664|1385912400000|       97259|     0.11314973|            null|            null|             null|             null|\n",
       "     8932|1385914800000|       88239|           null|            null|            null|             null|     0.0037177156|\n",
       "     8932|1385855400000|       88239|           null|            null|            null|             null|     0.0037177156|\n",
       "     8975|1385913000000|       88239|           null|            null|            null|             null|      0.054097105|\n",
       "     8979|1385914200000|       88239|           null|            null|            null|             null|        0.0356723|\n",
       "     8931|1385914800000|       88239|           null|            null|            null|             null|      0.053003322|\n",
       "     8977|1385914200000|       88239|           null|            null|            null|             null|      0.060942616|\n",
       "     8935|1385929200000|       88239|           null|            null|            null|             null|      0.018102609|\n",
       "     8985|1385892000000|       88239|           null|            null|            null|             null|      0.058486093|\n",
       "     8937|1385929200000|       88239|           null|            null|            null|             null|       0.10327051|\n",
       "+---------+-------------+------------+---------------+----------------+----------------+-----------------+-----------------+\n",
       "only showing top 20 rows\n",
       "\n",
       "+---------+-------------+------------+---------------+----------------+----------------+-----------------+-----------------+\n",
       "square_id|time_interval|country_code|sms_in_activity|sms_out_activity|call_in_activity|call_out_activity|internet_activity|\n",
       "+---------+-------------+------------+---------------+----------------+----------------+-----------------+-----------------+\n",
       "      457|1385916000000|           0|       0.388785|            null|            null|             null|             null|\n",
       "      457|1385928000000|           0|     0.10966566|            null|            null|             null|             null|\n",
       "      457|1385916600000|           0|      0.5287516|            null|            null|             null|             null|\n",
       "      457|1385915400000|           0|     0.27911934|            null|            null|       0.08321077|             null|\n",
       "      457|1385917200000|           0|    0.096438214|            null|            null|             null|             null|\n",
       "      457|1385904000000|           0|     0.08321077|            null|            null|             null|             null|\n",
       "      457|1385917800000|           0|    0.026454894|            null|            null|             null|             null|\n",
       "      457|1385905800000|           0|     0.26589188|            null|            null|             null|             null|\n",
       "      457|1385918400000|           0|     0.10966566|            null|            null|             null|             null|\n",
       "      457|1385907000000|           0|    0.013227447|            null|            null|             null|             null|\n",
       "      457|1385919000000|           0|     0.10966566|            null|            null|             null|             null|\n",
       "      457|1385908200000|           0|     0.26589188|            null|            null|             null|             null|\n",
       "      457|1385919600000|           0|     0.66405827|            null|            null|             null|             null|\n",
       "      457|1385909400000|           0|     0.10966566|            null|            null|             null|             null|\n",
       "      457|1385920200000|           0|      0.3623301|            null|            null|             null|             null|\n",
       "      457|1385911200000|           0|     0.08321077|            null|            null|             null|             null|\n",
       "      457|1385920800000|           0|     0.16642153|            null|            null|             null|             null|\n",
       "      457|1385913000000|           0|    0.013227447|            null|            null|             null|             null|\n",
       "      457|1385921400000|           0|    0.026454894|            null|            null|             null|             null|\n",
       "      457|1385914200000|           0|    0.013227447|            null|            null|             null|             null|\n",
       "+---------+-------------+------------+---------------+----------------+----------------+-----------------+-----------------+\n",
       "only showing top 20 rows\n",
       "\n",
       "+---------+-------------+------------+---------------+----------------+----------------+-----------------+-----------------+\n",
       "square_id|time_interval|country_code|sms_in_activity|sms_out_activity|call_in_activity|call_out_activity|internet_activity|\n",
       "+---------+-------------+------------+---------------+----------------+----------------+-----------------+-----------------+\n",
       "     3516|1385880000000|           0|     0.15421729|            null|            null|             null|             null|\n",
       "     3516|1385890200000|           0|      0.5280376|            null|            null|             null|             null|\n",
       "     3516|1385880600000|           0|     0.30843458|            null|            null|             null|             null|\n",
       "     3516|1385883600000|           0|     0.58094555|            null|            null|             null|             null|\n",
       "     3516|1385884200000|           0|      0.9962379|            null|            null|             null|             null|\n",
       "     3516|1385866200000|           0|    0.052907944|            null|            null|             null|             null|\n",
       "     3516|1385884800000|           0|      1.4126642|            null|            null|             null|             null|\n",
       "     3516|1385874000000|           0|     0.10581589|            null|            null|             null|             null|\n",
       "     3516|1385885400000|           0|       1.103778|            null|            null|             null|             null|\n",
       "     3516|1385859600000|           0|    0.006230752|            null|            null|             null|             null|\n",
       "     3516|1385886000000|           0|     0.07682172|            null|            null|      0.015942518|             null|\n",
       "     3516|1385881200000|           0|     0.72268504|            null|            null|             null|             null|\n",
       "     3516|1385886600000|           0|      1.3285537|            null|            null|             null|             null|\n",
       "     3516|1385882400000|           0|     0.41875702|            null|            null|             null|             null|\n",
       "     3516|1385887200000|           0|     0.76286817|            null|            null|      0.006230752|             null|\n",
       "     3516|1385889600000|           0|       0.527758|     0.007971259|            null|      0.018692257|             null|\n",
       "     3516|1385887800000|           0|      1.1601506|      0.15872383|            null|             null|             null|\n",
       "     3516|1385875200000|           0|           null|            null|            null|       0.15421729|             null|\n",
       "     3516|1385888400000|           0|     0.43295902|            null|            null|             null|             null|\n",
       "     3516|1385881800000|           0|     0.21163177|            null|            null|             null|             null|\n",
       "+---------+-------------+------------+---------------+----------------+----------------+-----------------+-----------------+\n",
       "only showing top 20 rows\n",
       "\n",
       "+---------+-------------+------------+---------------+----------------+----------------+-----------------+-----------------+\n",
       "square_id|time_interval|country_code|sms_in_activity|sms_out_activity|call_in_activity|call_out_activity|internet_activity|\n",
       "+---------+-------------+------------+---------------+----------------+----------------+-----------------+-----------------+\n",
       "     3367|1385912400000|       97259|     0.00790323|            null|            null|             null|             null|\n",
       "     3663|1385912400000|       97259|     0.24540168|            null|            null|             null|             null|\n",
       "     3467|1385912400000|       97259|     0.17073873|            null|            null|             null|             null|\n",
       "     3463|1385912400000|       97259|     0.45257905|            null|            null|             null|             null|\n",
       "     3368|1385912400000|       97259|      0.1628355|            null|            null|             null|             null|\n",
       "     3564|1385912400000|       97259|      0.5710262|            null|            null|             null|             null|\n",
       "     3562|1385912400000|       97259|      0.2631056|            null|            null|             null|             null|\n",
       "     3563|1385912400000|       97259|       0.752031|            null|            null|             null|             null|\n",
       "     3664|1385912400000|       97259|     0.11314973|            null|            null|             null|             null|\n",
       "     3462|1385912400000|       97259|      0.2098932|            null|            null|             null|             null|\n",
       "     3464|1385912400000|       97259|     0.19292864|            null|            null|             null|             null|\n",
       "     1002|1385886600000|       88239|           null|            null|            null|             null|       0.10178613|\n",
       "     1003|1385886600000|       88239|           null|            null|            null|             null|       0.09717833|\n",
       "     1001|1385887800000|       88239|           null|            null|            null|             null|       0.10178613|\n",
       "     1003|1385887200000|       88239|           null|            null|            null|             null|       0.21379234|\n",
       "        1|1385886600000|       88239|           null|            null|            null|             null|     0.0089365505|\n",
       "     1002|1385884800000|       88239|           null|            null|            null|             null|        0.2442867|\n",
       "     1002|1385887200000|       88239|           null|            null|            null|             null|       0.22392948|\n",
       "     1001|1385884800000|       88239|           null|            null|            null|             null|        0.2442867|\n",
       "     1002|1385887800000|       88239|           null|            null|            null|             null|       0.10178613|\n",
       "+---------+-------------+------------+---------------+----------------+----------------+-----------------+-----------------+\n",
       "only showing top 20 rows\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Note the difference between limit() and take(). limit() is a transformation and take() is an action.\n",
    "cdr.createOrReplaceTempView(\"cdrTable\")\n",
    "\n",
    "cdr5Rows = cdr.limit(5)\n",
    "cdr5Rows.show()\n",
    "cdr5Rows = spark.sql(\"\"\"\n",
    "  SELECT * \n",
    "  FROM cdrTable \n",
    "  LIMIT 5\n",
    "\"\"\")\n",
    "cdr5Rows.show()\n",
    "\n",
    "\n",
    "myCols = [\"square_id\", \"country_code\", \"call_out_activity\"]\n",
    "myColsDF = cdr.select(*myCols)\n",
    "spark.sql(\"\"\"\n",
    "  SELECT square_id,\n",
    "    country_code, \n",
    "    call_out_activity \n",
    "  FROM cdrTable\n",
    "\"\"\")\n",
    "allColsDF = cdr.select(F.col('*'))  # col('*') selects all the columns of DF\n",
    "\n",
    "\n",
    "droppedColsDF = cdr.drop(*myCols)\n",
    "# Cannot select all columns except a few, using SQL query.\n",
    "\n",
    "\n",
    "cdr.select('square_id', 'country_code').distinct().show()\n",
    "cdr.select('square_id', 'country_code').drop_duplicates().show()\n",
    "\n",
    "\n",
    "# sort and orderBY both take either a column name or a column object as argument.\n",
    "cdr.sort('country_code').show()\n",
    "cdr.sort(F.col('country_code')).show()\n",
    "cdr.sort('country_code', ascending=False).show()\n",
    "cdr.orderBy('country_code').show()\n",
    "cdr.orderBy(F.col('country_code')).show()\n",
    "cdr.orderBy(F.col('country_code'), ascending=False).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`df.colName` and `df['colName']` only creates column objects.**  \n",
    "`df.colName.show()` and `df['colName'].show()` will not work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create new columns in DataFrames\n",
    "These are transformations that take a df as input and create another df with derived columns as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+---------+-------------+------------+---------------+----------------+----------------+-----------------+-----------------+------------------+\n",
       "square_id|time_interval|country_code|sms_in_activity|sms_out_activity|call_in_activity|call_out_activity|internet_activity|         sms_ratio|\n",
       "+---------+-------------+------------+---------------+----------------+----------------+-----------------+-----------------+------------------+\n",
       "        1|1385852400000|          46|           null|            null|            null|             null|      0.026137425|              null|\n",
       "        1|1385853000000|          39|     0.16513683|      0.17639945|     0.030875085|      0.027300464|        13.330858|0.9361527194661042|\n",
       "        1|1385853600000|           0|    0.029087774|     0.027300464|            null|             null|             null|1.0654681351520536|\n",
       "+---------+-------------+------------+---------------+----------------+----------------+-----------------+-----------------+------------------+\n",
       "only showing top 3 rows\n",
       "\n",
       "+---------+-------------+------------+---------------+----------------+----------------+-----------------+-----------------+------------------+\n",
       "square_id|time_interval|country_code|sms_in_activity|sms_out_activity|call_in_activity|call_out_activity|internet_activity|         sms_ratio|\n",
       "+---------+-------------+------------+---------------+----------------+----------------+-----------------+-----------------+------------------+\n",
       "        1|1385852400000|          46|           null|            null|            null|             null|      0.026137425|              null|\n",
       "        1|1385853000000|          39|     0.16513683|      0.17639945|     0.030875085|      0.027300464|        13.330858|0.9361527194661042|\n",
       "        1|1385853600000|           0|    0.029087774|     0.027300464|            null|             null|             null|1.0654681351520536|\n",
       "+---------+-------------+------------+---------------+----------------+----------------+-----------------+-----------------+------------------+\n",
       "only showing top 3 rows\n",
       "\n",
       "+---------+-------------+------------+---------------+----------------+----------------+-----------------+-----------------+---------+\n",
       "square_id|time_interval|country_code|sms_in_activity|sms_out_activity|call_in_activity|call_out_activity|internet_activity|newColId2|\n",
       "+---------+-------------+------------+---------------+----------------+----------------+-----------------+-----------------+---------+\n",
       "        1|1385852400000|          46|           null|            null|            null|             null|      0.026137425|        3|\n",
       "        1|1385853000000|          39|     0.16513683|      0.17639945|     0.030875085|      0.027300464|        13.330858|        3|\n",
       "        1|1385853600000|           0|    0.029087774|     0.027300464|            null|             null|             null|        3|\n",
       "+---------+-------------+------------+---------------+----------------+----------------+-----------------+-----------------+---------+\n",
       "only showing top 3 rows\n",
       "\n",
       "+---------+-------------+------------+---------------+----------------+----------------+-----------------+-----------------+------+\n",
       "square_id|time_interval|country_code|sms_in_activity|sms_out_activity|call_in_activity|call_out_activity|internet_activity|newCol|\n",
       "+---------+-------------+------------+---------------+----------------+----------------+-----------------+-----------------+------+\n",
       "        1|1385852400000|          46|           null|            null|            null|             null|      0.026137425| 1  46|\n",
       "        1|1385853000000|          39|     0.16513683|      0.17639945|     0.030875085|      0.027300464|        13.330858| 1  39|\n",
       "        1|1385853600000|           0|    0.029087774|     0.027300464|            null|             null|             null|  1  0|\n",
       "+---------+-------------+------------+---------------+----------------+----------------+-----------------+-----------------+------+\n",
       "only showing top 3 rows\n",
       "\n",
       "+------+\n",
       "newCol|\n",
       "+------+\n",
       "  true|\n",
       " false|\n",
       " false|\n",
       "+------+\n",
       "only showing top 3 rows\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, concat, lit\n",
    "\n",
    "# The following two statements are equivalent\n",
    "(cdr\n",
    " .select(\n",
    "    F.col('*'), \n",
    "    (F.col('sms_in_activity') / F.col('sms_out_activity')).alias('sms_ratio')\n",
    "  )\n",
    " .show(3)\n",
    ")\n",
    "\n",
    "(cdr\n",
    "  .withColumn(\n",
    "    'sms_ratio', \n",
    "    F.col('sms_in_activity') / F.col('sms_out_activity')\n",
    "  )\n",
    "  .show(3)\n",
    ") \n",
    "\n",
    "cdr.withColumn('newColId2', F.col('square_id') + 2).show(3)\n",
    "# note the use of lit()\n",
    "cdr.withColumn(\"newCol\", F.concat(F.col('square_id'), F.lit('  '), F.col('country_code'))).show(3)\n",
    "\n",
    "cdr.select(F.col('sms_out_activity').isNull().alias('newCol')).show(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering a DataFrame\n",
    "\n",
    "`myDF.filter(sql like condition)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+---------+-------------+------------+---------------+----------------+----------------+-----------------+-----------------+\n",
       "square_id|time_interval|country_code|sms_in_activity|sms_out_activity|call_in_activity|call_out_activity|internet_activity|\n",
       "+---------+-------------+------------+---------------+----------------+----------------+-----------------+-----------------+\n",
       "        1|1385852400000|          46|           null|            null|            null|             null|      0.026137425|\n",
       "        1|1385853000000|          39|     0.16513683|      0.17639945|     0.030875085|      0.027300464|        13.330858|\n",
       "        1|1385853600000|          39|     0.18645109|      0.13658783|     0.054600928|             null|        11.329553|\n",
       "        1|1385854200000|          39|     0.21965227|      0.38112897|      0.08252566|       0.13596356|       13.1661625|\n",
       "        1|1385854800000|          39|      0.2951142|       0.1104504|     0.054600928|      0.079575315|        13.321653|\n",
       "+---------+-------------+------------+---------------+----------------+----------------+-----------------+-----------------+\n",
       "only showing top 5 rows\n",
       "\n",
       "+---------+-------------+------------+---------------+----------------+----------------+-----------------+-----------------+\n",
       "square_id|time_interval|country_code|sms_in_activity|sms_out_activity|call_in_activity|call_out_activity|internet_activity|\n",
       "+---------+-------------+------------+---------------+----------------+----------------+-----------------+-----------------+\n",
       "        1|1385852400000|          46|           null|            null|            null|             null|      0.026137425|\n",
       "        1|1385854800000|          46|           null|            null|            null|             null|      0.026137425|\n",
       "        1|1385856600000|          46|           null|            null|            null|             null|      0.026137425|\n",
       "        1|1385858400000|          46|           null|            null|            null|             null|      0.026137425|\n",
       "        1|1385860800000|          46|           null|            null|            null|             null|      0.026137425|\n",
       "+---------+-------------+------------+---------------+----------------+----------------+-----------------+-----------------+\n",
       "only showing top 5 rows\n",
       "\n",
       "+---------+-------------+------------+---------------+----------------+----------------+-----------------+-----------------+\n",
       "square_id|time_interval|country_code|sms_in_activity|sms_out_activity|call_in_activity|call_out_activity|internet_activity|\n",
       "+---------+-------------+------------+---------------+----------------+----------------+-----------------+-----------------+\n",
       "        1|1385852400000|          46|           null|            null|            null|             null|      0.026137425|\n",
       "        1|1385854800000|          46|           null|            null|            null|             null|      0.026137425|\n",
       "        1|1385856600000|          46|           null|            null|            null|             null|      0.026137425|\n",
       "        1|1385858400000|          46|           null|            null|            null|             null|      0.026137425|\n",
       "        1|1385860800000|          46|           null|            null|            null|             null|      0.026137425|\n",
       "+---------+-------------+------------+---------------+----------------+----------------+-----------------+-----------------+\n",
       "only showing top 5 rows\n",
       "\n",
       "+---------+-------------+------------+---------------+----------------+----------------+-----------------+-----------------+\n",
       "square_id|time_interval|country_code|sms_in_activity|sms_out_activity|call_in_activity|call_out_activity|internet_activity|\n",
       "+---------+-------------+------------+---------------+----------------+----------------+-----------------+-----------------+\n",
       "        1|1385852400000|          46|           null|            null|            null|             null|      0.026137425|\n",
       "        1|1385854800000|          46|           null|            null|            null|             null|      0.026137425|\n",
       "        1|1385856600000|          46|           null|            null|            null|             null|      0.026137425|\n",
       "        1|1385858400000|          46|           null|            null|            null|             null|      0.026137425|\n",
       "        1|1385860800000|          46|           null|            null|            null|             null|      0.026137425|\n",
       "+---------+-------------+------------+---------------+----------------+----------------+-----------------+-----------------+\n",
       "only showing top 5 rows\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# SQL style condition\n",
    "(cdr.filter(\"country_code in (46, 39)\").show(5))\n",
    "(cdr.where(\"sms_out_activity is null and sms_in_activity is null\")\n",
    "    .show(5)\n",
    ")\n",
    "\n",
    "# use col() to create condition\n",
    "cdr.filter(F.col('sms_in_activity').isNull() & F.col('sms_out_activity').isNull()).show(5)\n",
    "cdr.where(F.col('sms_in_activity').isNull() & F.col('sms_out_activity').isNull()).show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rename columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+---------+-------------+------------+---------------+----------------+----------------+-----------------+-----------------+\n",
       "square.id|time.interval|country.code|sms.in.activity|sms.out.activity|call.in.activity|call.out.activity|internet.activity|\n",
       "+---------+-------------+------------+---------------+----------------+----------------+-----------------+-----------------+\n",
       "        1|1385852400000|          46|           null|            null|            null|             null|      0.026137425|\n",
       "        1|1385853000000|          39|     0.16513683|      0.17639945|     0.030875085|      0.027300464|        13.330858|\n",
       "        1|1385853600000|           0|    0.029087774|     0.027300464|            null|             null|             null|\n",
       "        1|1385853600000|          39|     0.18645109|      0.13658783|     0.054600928|             null|        11.329553|\n",
       "        1|1385854200000|          39|     0.21965227|      0.38112897|      0.08252566|       0.13596356|       13.1661625|\n",
       "+---------+-------------+------------+---------------+----------------+----------------+-----------------+-----------------+\n",
       "only showing top 5 rows\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Using select, col and alias\n",
    "(cdr\n",
    "  .select(\n",
    "    \"square_id\",\n",
    "    F.col(\"time_interval\").alias(\"ts\"), \n",
    "    \"country_code\"\n",
    "  )\n",
    ")\n",
    "\n",
    "# Using withColumnRenamed()\n",
    "# all the columns of cdr will be present in the resultant DF along with the renamed column.\n",
    "(cdr\n",
    "  .withColumnRenamed(\"time_interval\", \"ts\")\n",
    ")\n",
    "\n",
    "# rename all columns with the same expression\n",
    "cdr.select(*[F.col(c).alias(c.replace('_', '.')) for c in cdr.columns]).show(5)\n",
    "\n",
    "# rename multiple columns\n",
    "# mySDF.select([F.col(oldColName).alias(newColName) for oldColName, newColName in zip(oldColNames, newColNames)])\n",
    "\n",
    "# A single withColumnRenamed cannot be used to rename multiple column names.\n",
    "data = sqlContext.createDataFrame([(1,2), (3,4)], ['x1', 'x2'])\n",
    "data = (data\n",
    "       .withColumnRenamed('x1','x3')\n",
    "       .withColumnRenamed('x2', 'x4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "functions module in pyspark\n",
    "https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#module-pyspark.sql.functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+---------+-------------+------------+---------------+----------------+----------------+-----------------+-----------------+-------------------+----------+----------+\n",
       "square_id|time_interval|country_code|sms_in_activity|sms_out_activity|call_in_activity|call_out_activity|internet_activity|                 ts|     date1|     date2|\n",
       "+---------+-------------+------------+---------------+----------------+----------------+-----------------+-----------------+-------------------+----------+----------+\n",
       "        1|1385852400000|          46|           null|            null|            null|             null|      0.026137425|2013-11-30 23:00:00|2013-11-30|2013/11/30|\n",
       "        1|1385853000000|          39|     0.16513683|      0.17639945|     0.030875085|      0.027300464|        13.330858|2013-11-30 23:10:00|2013-11-30|2013/11/30|\n",
       "        1|1385853600000|           0|    0.029087774|     0.027300464|            null|             null|             null|2013-11-30 23:20:00|2013-11-30|2013/11/30|\n",
       "        1|1385853600000|          39|     0.18645109|      0.13658783|     0.054600928|             null|        11.329553|2013-11-30 23:20:00|2013-11-30|2013/11/30|\n",
       "        1|1385854200000|          39|     0.21965227|      0.38112897|      0.08252566|       0.13596356|       13.1661625|2013-11-30 23:30:00|2013-11-30|2013/11/30|\n",
       "+---------+-------------+------------+---------------+----------------+----------------+-----------------+-----------------+-------------------+----------+----------+\n",
       "only showing top 5 rows\n",
       "\n",
       "+---------+-------------+------------+---------------+----------------+----------------+-----------------+-----------------+-------------------+----+-----+---------+---------+\n",
       "square_id|time_interval|country_code|sms_in_activity|sms_out_activity|call_in_activity|call_out_activity|internet_activity|                 ts|year|month|dayofyear|dayofweek|\n",
       "+---------+-------------+------------+---------------+----------------+----------------+-----------------+-----------------+-------------------+----+-----+---------+---------+\n",
       "        1|1385852400000|          46|           null|            null|            null|             null|      0.026137425|2013-11-30 23:00:00|2013|   11|      334|        7|\n",
       "        1|1385853000000|          39|     0.16513683|      0.17639945|     0.030875085|      0.027300464|        13.330858|2013-11-30 23:10:00|2013|   11|      334|        7|\n",
       "        1|1385853600000|           0|    0.029087774|     0.027300464|            null|             null|             null|2013-11-30 23:20:00|2013|   11|      334|        7|\n",
       "        1|1385853600000|          39|     0.18645109|      0.13658783|     0.054600928|             null|        11.329553|2013-11-30 23:20:00|2013|   11|      334|        7|\n",
       "        1|1385854200000|          39|     0.21965227|      0.38112897|      0.08252566|       0.13596356|       13.1661625|2013-11-30 23:30:00|2013|   11|      334|        7|\n",
       "+---------+-------------+------------+---------------+----------------+----------------+-----------------+-----------------+-------------------+----+-----+---------+---------+\n",
       "only showing top 5 rows\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example of applying functions on columns of DF\n",
    "\n",
    "# 1. Convert time_interval string to timestamp type and create a new column that extracts the date from timestamp  \n",
    "# 2. Extract year, month, and dayofyear\n",
    "\n",
    "from pyspark.sql.functions import unix_timestamp, to_date, date_format, month, year, dayofyear, dayofweek\n",
    "from pyspark.sql.types import TimestampType\n",
    "\n",
    "(cdr.withColumn(\"ts\", (F.col(\"time_interval\")/1000).cast(TimestampType()))\n",
    "    .withColumn(\"date1\", to_date(F.col(\"ts\")))\n",
    "    .withColumn(\"date2\", F.date_format(F.col(\"date1\"), 'yyyy/MM/dd'))\n",
    ").show(5)\n",
    "\n",
    "(cdr.withColumn(\"ts\", (F.col(\"time_interval\")/1000).cast(TimestampType()))\n",
    "    .select(F.col(\"*\"), \n",
    "            F.year(F.col(\"ts\")).alias(\"year\"),\n",
    "            F.month(F.col(\"ts\")).alias(\"month\"),\n",
    "            F.dayofyear(F.col(\"ts\")).alias(\"dayofyear\"),\n",
    "            F.dayofweek(F.col(\"ts\")).alias(\"dayofweek\"))\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregation\n",
    "\n",
    "The `groupBy()` function is a **wide** transformation - it will produce a shuffle and conclude a stage boundary.\n",
    "\n",
    "Unlike all of the other transformations we've seen so far, this transformation does not return a `DataFrame`. In Python it returns `GroupedData`\n",
    "\n",
    "`groupBy()` supports the following aggregations:\n",
    "\n",
    "| Method | Description |\n",
    "|--------|-------------|\n",
    "| `avg(..)` | Compute the mean value for each numeric columns for each group. |\n",
    "| `count(..)` | Count the number of rows for each group. |\n",
    "| `sum(..)` | Compute the sum for each numeric columns for each group. |\n",
    "| `min(..)` | Compute the min value for each numeric column for each group. |\n",
    "| `max(..)` | Compute the max value for each numeric columns for each group. |\n",
    "| `mean(..)` | Compute the average value for each numeric columns for each group. |\n",
    "| `agg(..)` | Compute aggregates by specifying a series of aggregate columns. |\n",
    "| `pivot(..)` | Pivots a column of the current DataFrame and perform the specified aggregation. |\n",
    "\n",
    "Functions:\n",
    "https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#module-pyspark.sql.functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+---------+-------------------+\n",
       "square_id|sms_in_activity_min|\n",
       "+---------+-------------------+\n",
       "     1088|        0.020871513|\n",
       "     1238|        0.028927796|\n",
       "     1342|         0.07374897|\n",
       "+---------+-------------------+\n",
       "only showing top 3 rows\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cdr.createOrReplaceTempView(\"cdrTable\")\n",
    "spark.sql(\"\"\"\n",
    "  SELECT square_id,\n",
    "    MIN(sms_in_activity) AS sms_in_activity_min\n",
    "  FROM cdrTable\n",
    "  GROUP BY square_id\n",
    "\"\"\").show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+---------+-----------+-------------------+\n",
       "square_id|       col1|               col2|\n",
       "+---------+-----------+-------------------+\n",
       "     1088|0.020871513|0.10223620312242973|\n",
       "     1238|0.028927796|0.38883448656806613|\n",
       "     1342| 0.07374897|  0.256445283239538|\n",
       "+---------+-----------+-------------------+\n",
       "only showing top 3 rows\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(cdr\n",
    "  .groupby(\"square_id\")\n",
    "  .agg(\n",
    "    F.min(F.col(\"sms_in_activity\")).alias('col1'),\n",
    "    F.avg(F.col(\"sms_in_activity\")).alias('col2'),\n",
    "  )\n",
    ").show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+---------+-------------------+--------------------+---------------------+-------------------+--------------------+---------------------+\n",
       "square_id|sms_in_activity_min|sms_out_activity_min|internet_activity_min|sms_in_activity_max|sms_out_activity_max|internet_activity_max|\n",
       "+---------+-------------------+--------------------+---------------------+-------------------+--------------------+---------------------+\n",
       "     1088|        0.020871513|         0.020871513|          0.020871513|         0.44581017|          0.43863675|            11.037694|\n",
       "     1238|        0.028927796|         0.028927796|          0.028927796|          1.4988595|           1.0689774|             36.07335|\n",
       "     1342|         0.07374897|          0.07374897|           0.07374897|          1.4012305|          0.88498765|            42.553158|\n",
       "+---------+-------------------+--------------------+---------------------+-------------------+--------------------+---------------------+\n",
       "only showing top 3 rows\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "agg_cols = ['sms_in_activity', 'sms_out_activity','internet_activity']\n",
    "\n",
    "(cdr\n",
    "  .groupby(\"square_id\")\n",
    "  .agg(\n",
    "    *[F.min(F.col(c)).alias(c+'_min') for c in agg_cols], \n",
    "    *[F.max(F.col(c)).alias(c+'_max')  for c in agg_cols],\n",
    "  )\n",
    ").show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+----+----+----+----+\n",
       "col1|col2|col3|col4|\n",
       "+----+----+----+----+\n",
       "   a|  aa|   1|  11|\n",
       "   a|  aa|   2|  12|\n",
       "   a|  bb|   3|  13|\n",
       "   a|  bb|   4|  14|\n",
       "   b|  aa|   5|  15|\n",
       "   b|  aa|   6|  16|\n",
       "   b|  bb|   7|  17|\n",
       "   b|  bb|   8|  18|\n",
       "+----+----+----+----+\n",
       "\n",
       "+----+----+-------+-------+\n",
       "col1|col2|sumCol3|avgCol4|\n",
       "+----+----+-------+-------+\n",
       "   a|  aa|      3|   11.5|\n",
       "   a|  bb|      7|   13.5|\n",
       "   b|  aa|     11|   15.5|\n",
       "   b|  bb|     15|   17.5|\n",
       "+----+----+-------+-------+\n",
       "\n",
       "+----+---------+---------+\n",
       "col1|sum(col3)|sum(col4)|\n",
       "+----+---------+---------+\n",
       "   b|       26|       66|\n",
       "   a|       10|       50|\n",
       "+----+---------+---------+\n",
       "\n",
       "+----+----+-----+\n",
       "col1|col2|nRows|\n",
       "+----+----+-----+\n",
       "   a|  aa|    2|\n",
       "   a|  bb|    2|\n",
       "   b|  aa|    2|\n",
       "   b|  bb|    2|\n",
       "+----+----+-----+\n",
       "\n",
       "+----+----+--------+--------+--------+--------+\n",
       "col1|col2|min_col3|min_col4|max_col3|max_col4|\n",
       "+----+----+--------+--------+--------+--------+\n",
       "   b|  aa|       5|      15|       6|      16|\n",
       "   a|  aa|       1|      11|       2|      12|\n",
       "   b|  bb|       7|      17|       8|      18|\n",
       "   a|  bb|       3|      13|       4|      14|\n",
       "+----+----+--------+--------+--------+--------+\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# In the above examples we used column objects as arguments to the agrregation functions like min, max... Instead, column names can also be passed as arguments.\n",
    "\n",
    "df2 = sqlContext.createDataFrame(\n",
    "  [('a', 'aa', 1, 11), ('a', 'aa', 2, 12), ('a', 'bb', 3, 13), ('a', 'bb', 4, 14), ('b', 'aa', 5, 15), ('b', 'aa', 6, 16), ('b', 'bb', 7, 17), ('b', 'bb', 8, 18)],\n",
    "  ('col1', 'col2', 'col3', 'col4')\n",
    ")\n",
    "df2.show()\n",
    "\n",
    "(df2.groupBy(['col1', 'col2'])\n",
    "  .agg(\n",
    "    F.sum('col3').alias('sumCol3'), \n",
    "    F.avg('col4').alias('avgCol4')\n",
    "  )\n",
    "  .sort('col1', 'col2')\n",
    "  .show()\n",
    ")\n",
    "\n",
    "# Apply the same aggegation function to all columns of a df\n",
    "df2.groupBy('col1').sum().show()\n",
    "# Notice that sum is being done only on 'col3' and 'col4' and not on 'col2' because 'col2' is of type string and not numeric.\n",
    "\n",
    "# Count the no of rows in each group\n",
    "(df2.groupBy(['col1', 'col2'])\n",
    "  .agg(\n",
    "    F.count('*').alias('nRows')\n",
    "  )\n",
    "  .sort('col1', 'col2')\n",
    "  .show()\n",
    ")\n",
    "\n",
    "minColNames = ['col3', 'col4']\n",
    "maxColNames = ['col3', 'col4']\n",
    "(df2.groupBy(['col1', 'col2'])\n",
    "  .agg(\n",
    "    *[F.min(c).alias('min_' + c) for c in minColNames],\n",
    "    *[F.max(c).alias('max_' + c) for c in maxColNames]\n",
    "  )\n",
    "  .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UDFs\n",
    "\n",
    "These user-defined functions (udfs) operate one-row-at-a-time, and thus suffer from high serialization and invocation overhead. As a result, many data pipelines define UDFs in Java and Scala and then invoke them from Python.  \n",
    "This section is presented here only for the sake of completeness. **Use scalar pandas udfs instead of these row-at-a-time udfs.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">root\n",
       "-- integers: long (nullable = true)\n",
       "-- floats: double (nullable = true)\n",
       "-- integer_arrays: array (nullable = true)\n",
       "    |-- element: long (containsNull = true)\n",
       "\n",
       "+--------+------+--------------+\n",
       "integers|floats|integer_arrays|\n",
       "+--------+------+--------------+\n",
       "       1|  -1.0|        [1, 2]|\n",
       "       2|   0.5|     [3, 4, 5]|\n",
       "       3|   2.7|  [6, 7, 8, 9]|\n",
       "+--------+------+--------------+\n",
       "\n",
       "+--------+------+----------+------------+\n",
       "integers|floats|intSquared|floatSquared|\n",
       "+--------+------+----------+------------+\n",
       "       1|  -1.0|         1|        null|\n",
       "       2|   0.5|         4|        null|\n",
       "       3|   2.7|         9|        null|\n",
       "+--------+------+----------+------------+\n",
       "\n",
       "+--------+---------------+\n",
       "integers|    floatsArray|\n",
       "+--------+---------------+\n",
       "       1|[1.0, 2.0, 1.0]|\n",
       "       2|[2.0, 3.0, 4.0]|\n",
       "       3|[3.0, 4.0, 9.0]|\n",
       "+--------+---------------+\n",
       "\n",
       "+--------+------+\n",
       "integers|struct|\n",
       "+--------+------+\n",
       "       1|[1, b]|\n",
       "       2|[2, c]|\n",
       "       3|[3, d]|\n",
       "+--------+------+\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "import pandas as pd\n",
    "import string\n",
    "\n",
    "# example data\n",
    "df_pd = pd.DataFrame(\n",
    "    data={'integers': [1, 2, 3],\n",
    "     'floats': [-1.0, 0.5, 2.7],\n",
    "     'integer_arrays': [[1, 2], [3, 4, 5], [6, 7, 8, 9]]}\n",
    ")\n",
    "df = spark.createDataFrame(df_pd)\n",
    "df.printSchema()\n",
    "df.show()\n",
    "\n",
    "def mySquare(x):\n",
    "  return x**2\n",
    "\n",
    "def returnList(x):\n",
    "  return [float(x), float(x + 1), float(x * x)]\n",
    "\n",
    "def intToAscii(number):\n",
    "  return [number, string.ascii_letters[number]]\n",
    "\n",
    "arraySchema = T.StructType([\n",
    "    T.StructField('number', T.IntegerType(), nullable=False),\n",
    "    T.StructField('letters', T.StringType(), nullable=False)\n",
    "])\n",
    "\n",
    "# If the return type is not specified while declaring a function as udf, the default datatype of the output will be string.\n",
    "\n",
    "squareUdfInt = F.udf(mySquare, returnType=T.IntegerType())\n",
    "UdfReturnArray = F.udf(returnList, returnType=T.ArrayType(T.FloatType()))\n",
    "UdfReturnStruct = F.udf(intToAscii, returnType=arraySchema)\n",
    "\n",
    "df.select(\n",
    "  'integers',\n",
    "  'floats',\n",
    "  squareUdfInt('integers').alias('intSquared'),\n",
    "  squareUdfInt('floats').alias('floatSquared')\n",
    ").show()\n",
    "# floatSquared is Null because the udf is defined to return IntegerType but the return value is not IntergerType when 'floats' is the argument to the udf.\n",
    "\n",
    "# Return type is a composite type. All the elements in the composite type have the same data type (Array).\n",
    "df.select(\n",
    "  'integers',\n",
    "  UdfReturnArray('integers').alias('floatsArray')\n",
    ").show()\n",
    "\n",
    "\n",
    "# Return type is composite. Elements of the composite type have different data types.\n",
    "df.select(\n",
    "  'integers',\n",
    "  UdfReturnStruct('integers').alias('struct')\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas UDFs\n",
    "## Scalar pandas udfs\n",
    "\n",
    "https://databricks.com/blog/2017/10/30/introducing-vectorized-udfs-for-pyspark.html\n",
    "\n",
    "They are used for vectorizing scalar operations. To define a scalar Pandas UDF, simply use @pandas_udf to annotate a Python function that takes in `pandas.Series` as arguments and returns another `pandas.Series` of the same size. \n",
    "\n",
    "A scalar UDF defines a transformation: **One or more** `pandas.Series` -> A `pandas.Series`. The length of the returned pandas.Series must be of the same as the input pandas.Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+---+-------------------+\n",
       " id|                  v|\n",
       "+---+-------------------+\n",
       "  0| 0.6538091412794944|\n",
       "  0| 0.1744976470056887|\n",
       "  0| 0.8923911618313422|\n",
       "  0|0.30875434332032914|\n",
       "  0|0.25346628052933295|\n",
       "+---+-------------------+\n",
       "only showing top 5 rows\n",
       "\n",
       "10000000\n",
       "1000\n",
       "+---+--------+\n",
       " id|count(v)|\n",
       "+---+--------+\n",
       "148|   10000|\n",
       "463|   10000|\n",
       "471|   10000|\n",
       "496|   10000|\n",
       "833|   10000|\n",
       "+---+--------+\n",
       "only showing top 5 rows\n",
       "\n",
       "+---+------------------+------------------+\n",
       " id|                 v|             v + 1|\n",
       "+---+------------------+------------------+\n",
       "  0|0.6538091412794944|1.6538091412794944|\n",
       "  0|0.1744976470056887|1.1744976470056887|\n",
       "  0|0.8923911618313422| 1.892391161831342|\n",
       "+---+------------------+------------------+\n",
       "only showing top 3 rows\n",
       "\n",
       "+---+------------------+------------------+\n",
       " id|                 v|             v + 1|\n",
       "+---+------------------+------------------+\n",
       "  0|0.6538091412794944|1.6538091412794944|\n",
       "  0|0.1744976470056887|1.1744976470056887|\n",
       "  0|0.8923911618313422| 1.892391161831342|\n",
       "+---+------------------+------------------+\n",
       "only showing top 3 rows\n",
       "\n",
       "+---+------------------+------------------+\n",
       " id|                 v|             v + v|\n",
       "+---+------------------+------------------+\n",
       "  0|0.6538091412794944|1.3076182825589888|\n",
       "  0|0.1744976470056887|0.3489952940113774|\n",
       "  0|0.8923911618313422|1.7847823236626843|\n",
       "+---+------------------+------------------+\n",
       "only showing top 3 rows\n",
       "\n",
       "+---+------------------+------------------+\n",
       " id|                 v|             v + v|\n",
       "+---+------------------+------------------+\n",
       "  0|0.6538091412794944|1.3076182825589888|\n",
       "  0|0.1744976470056887|0.3489952940113774|\n",
       "  0|0.8923911618313422|1.7847823236626843|\n",
       "+---+------------------+------------------+\n",
       "only showing top 3 rows\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pyspark.sql.types as T\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "df = spark.range(0, 10 * 1000 * 1000).withColumn('id', (F.col('id') / 10000).cast('integer')).withColumn('v', F.rand())\n",
    "df.cache()\n",
    "df.show(5)\n",
    "print((df.count()))\n",
    "print(df.select(\"id\").distinct().count())\n",
    "df.groupBy('id').agg(F.count(F.col('v'))).show(5)\n",
    "\n",
    "def plusOne(v):\n",
    "    return v + 1\n",
    "\n",
    "def addTwoCols(v1, v2):\n",
    "    return v1 + v2\n",
    "  \n",
    "# Row-at-a-time udf\n",
    "# Input/output are both a scalar value (type \"double\" in this example)\n",
    "plusOneUdf = F.udf(plusOne, returnType=T.DoubleType())\n",
    "df.withColumn('v + 1', plusOneUdf(df.v)).show(3)\n",
    "\n",
    "# Scalar Pandas UDF\n",
    "# Input/output are both a pandas.Series of doubles\n",
    "plusOnePandasUdf = F.pandas_udf(plusOne, returnType=T.DoubleType(), functionType=F.PandasUDFType.SCALAR )\n",
    "df.withColumn('v + 1', plusOnePandasUdf(df.v)).show(3)\n",
    "\n",
    "\n",
    "# Row-at-a-time udf\n",
    "addTwoColsUDF = F.udf(addTwoCols, returnType=T.DoubleType())\n",
    "df.withColumn('v + v', addTwoColsUDF(df.v, df.v)).show(3)\n",
    "\n",
    "# Scalar Pandas UDF\n",
    "addTwoColsPUDF = F.pandas_udf(addTwoCols, returnType=T.DoubleType(), functionType=F.PandasUDFType.SCALAR )\n",
    "df.withColumn(\"v + v\", addTwoColsPUDF(F.col('v'), F.col('v'))).show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The examples above define a row-at-a-time UDF \"plusOneUdf\" and a scalar Pandas UDF \"plusOnePandasUdf\" that performs the same “plus one” computation.  \n",
    "\n",
    "**In the row-at-a-time version, the user-defined function takes a double “v” and returns the result of “v + 1” as a double. In the Pandas version, the user-defined function takes a `pandas.Series` “v” and returns the result of “v + 1” as a `pandas.Series`. Because “v + 1” is vectorized on `pandas.Series`, the Pandas version is much faster than the row-at-a-time version.**\n",
    "\n",
    "Note that there are two important requirements when using scalar pandas UDFs:\n",
    "\n",
    "* The input and output series must have the same size.\n",
    "* How a column is split into multiple `pandas.Series` is internal to Spark, and therefore the result of user-defined function must be independent of the splitting.\n",
    "\n",
    "Decorators can be used with python functions instead of declaring user-defined functions:  \n",
    "```\n",
    "@F.udf('double')\n",
    "def plusOne(v):\n",
    "    return v + 1\n",
    "\n",
    "@F.pandas_udf(\"double\", F.PandasUDFType.SCALAR)\n",
    "def pandasPlusOne(v):\n",
    "    return v + 1\n",
    "```\n",
    "\n",
    "Default value of the argument `functionType` for the function `pandas_udf` is `PandasUDFType.SCALAR`.\n",
    "\n",
    "`MapType`, `StructType` are currently not supported as output types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouped Map pandas udf\n",
    "\n",
    "Grouped map Pandas UDFs first splits a Spark DataFrame into groups based on the conditions specified in the groupby operator, applies a user-defined function (`pandas.DataFrame` -> `pandas.DataFrame`) to each group, combines and returns the results as a new Spark DataFrame.  \n",
    "A grouped map UDF defines transformation: A `pandas.DataFrame` -> A `pandas.DataFrame`.  The returnType should be a `StructType` describing the schema of the returned `pandas.DataFrame`. \n",
    "\n",
    "The column labels of the returned `pandas.DataFrame` must either match the field names in the defined returnType schema if specified as strings, or match the field data types by position if not strings, e.g. integer indices. \n",
    "\n",
    "The length of the returned pandas.DataFrame can be arbitrary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+---+--------------------+\n",
       " id|                   v|\n",
       "+---+--------------------+\n",
       "148| 0.39198942914391477|\n",
       "148|  0.2659805758775887|\n",
       "148|-0.30177763177755856|\n",
       "+---+--------------------+\n",
       "only showing top 3 rows\n",
       "\n",
       "test1\n",
       "10000000\n",
       "test2\n",
       "Out[35]: 10000000</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Input/output are both a pandas.DataFrame\n",
    "def subtractMean(pdf):\n",
    "    return pdf.assign(v=pdf.v - pdf.v.mean())\n",
    "\n",
    "subtractMeanPandasUdf = F.pandas_udf(subtractMean, returnType=df.schema, functionType=F.PandasUDFType.GROUPED_MAP)\n",
    "df.groupby('id').apply(subtractMeanPandasUdf).show(3)\n",
    "\n",
    "\n",
    "print(df.count())\n",
    "\n",
    "df.groupby('id').apply(subtractMeanPandasUdf).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, the user can define a function that takes two arguments. In this case, the grouping key(s) will be passed as the first argument and the data will be passed as the second argument. The grouping key(s) will be passed as a tuple (tuple because grouping can be done on more than one column/key) of numpy data types, e.g., `numpy.int32` and `numpy.float64`. The data will still be passed in as a `pandas.DataFrame` containing all columns from the original Spark DataFrame. This is useful when the user does not want to hardcode grouping key(s) in the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+---+---+\n",
       " id|  v|\n",
       "+---+---+\n",
       "  1|1.5|\n",
       "  2|6.0|\n",
       "+---+---+\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql.functions import pandas_udf, PandasUDFType\n",
    "\n",
    "df = spark.createDataFrame(\n",
    "    [(1, 1.0), (1, 2.0), (2, 3.0), (2, 5.0), (2, 10.0)],\n",
    "    (\"id\", \"v\")\n",
    ")\n",
    "@pandas_udf(\"id long, v double\", PandasUDFType.GROUPED_MAP)  # doctest: +SKIP\n",
    "def mean_udf(key, pdf):\n",
    "    # key is a tuple of one numpy.int64, which is the value\n",
    "    # of 'id' for the current group\n",
    "    return pd.DataFrame([key + (pdf.v.mean(),)])\n",
    "  \n",
    "df.groupby('id').apply(mean_udf).show()\n",
    "# column names of the output dataFrame are determined by the schema mentioned in the decorator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code note that:\n",
    "```\n",
    ">>> (1,) + (2,)\n",
    "(1, 2)\n",
    ">>> [(1,) + (2,)]\n",
    "[(1, 2)]\n",
    ">>> pd.DataFrame([(1, 2), (3, 4)])\n",
    "   0  1\n",
    "0  1  2\n",
    "1  3  4\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+---+-----------+----+\n",
       " id|ceil(v / 2)|   v|\n",
       "+---+-----------+----+\n",
       "  2|          5|10.0|\n",
       "  1|          1| 3.0|\n",
       "  2|          3| 5.0|\n",
       "  2|          2| 3.0|\n",
       "+---+-----------+----+\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@pandas_udf(\n",
    "  \"id long, `ceil(v / 2)` long, v double\", \n",
    "  PandasUDFType.GROUPED_MAP\n",
    ")\n",
    "def sum_udf(key, pdf):\n",
    "  # key is a tuple of two numpy.int64s, which is the values\n",
    "  # of 'id' and 'ceil(df.v / 2)' for the current group\n",
    "  return pd.DataFrame([key + (pdf.v.sum(),)])\n",
    "\n",
    "df.groupby(df.id, F.ceil(df.v / 2)).apply(sum_udf).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code, since id is `[1, 1, 2, 2, 3]` and ceil of v / 2 is `[1, 1, 2, 3, 5]` and grouping is on `[id, ceil(v/2)]` the keys are `[(1, 1), (2, 2), (2, 3), (3, 5)]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouped Aggregate pandas udf\n",
    "A grouped aggregate UDF defines a transformation: **One or more `pandas.Series` -> A `scalar`**. The returned scalar can be either a python primitive type, e.g., int or float or a numpy data type, e.g., numpy.int64 or numpy.float64.\n",
    "\n",
    "`MapType` and `StructType` are currently not supported as output types.\n",
    "\n",
    "Grouped aggregate UDFs are used with `pyspark.sql.GroupedData.agg()` and `pyspark.sql.Window`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+---+-----------+\n",
       " id|mean_udf(v)|\n",
       "+---+-----------+\n",
       "  1|        1.5|\n",
       "  2|        6.0|\n",
       "+---+-----------+\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@pandas_udf(\"double\", PandasUDFType.GROUPED_AGG)\n",
    "def mean_udf(v):\n",
    "    return v.mean()\n",
    "df.groupby(\"id\").agg(mean_udf(df['v'])).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouped map pandas_udf as substitute for pandas transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+----+----+----+\n",
       "col1|col2|col3|\n",
       "+----+----+----+\n",
       "   a| 2.0| 3.0|\n",
       "   a| 5.0| 6.0|\n",
       "   b| 8.0| 9.0|\n",
       "   b| 1.0| 3.0|\n",
       "+----+----+----+\n",
       "\n",
       "+----+----+----+-----------------+-----------------+----------------+----------------+\n",
       "col1|col2|col3|col2_to_mean_col1|col3_to_mean_col1|col2_to_std_col1|col3_to_std_col1|\n",
       "+----+----+----+-----------------+-----------------+----------------+----------------+\n",
       "   b| 8.0| 9.0|        1.7777778|              1.5|       1.6162441|       2.1213205|\n",
       "   b| 1.0| 3.0|       0.22222222|              0.5|      0.20203051|       0.7071068|\n",
       "   a| 2.0| 3.0|        0.5714286|        0.6666667|       0.9428091|       1.4142137|\n",
       "   a| 5.0| 6.0|        1.4285715|        1.3333334|       2.3570228|       2.8284273|\n",
       "+----+----+----+-----------------+-----------------+----------------+----------------+\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfSchema = T.StructType([\n",
    "  T.StructField('col1', T.StringType(), True),\n",
    "  T.StructField('col2', T.FloatType(), True),\n",
    "  T.StructField('col3', T.FloatType(), True)\n",
    "])\n",
    "\n",
    "df = spark.createDataFrame(data=[('a', 2.0, 3.0), ('a', 5.0, 6.0), ('b', 8.0, 9.0), ('b', 1.0, 3.0)], schema=dfSchema)\n",
    "df.show()\n",
    "\n",
    "to_append = [\n",
    "  T.StructField(\"col2_to_mean_col1\", T.FloatType(), True),\n",
    "  T.StructField(\"col3_to_mean_col1\", T.FloatType(), True),\n",
    "  T.StructField(\"col2_to_std_col1\", T.FloatType(), True),\n",
    "  T.StructField(\"col3_to_std_col1\", T.FloatType(), True),\n",
    "] \n",
    "newDfSchema = T.StructType(df.schema.fields + to_append)\n",
    "\n",
    "@F.pandas_udf(newDfSchema, F.PandasUDFType.GROUPED_MAP)\n",
    "def transformMean(df):\n",
    "  df['col2_to_mean_col1'] = df['col2'] / df['col2'].mean()\n",
    "  df['col3_to_mean_col1'] = df['col3'] / df['col3'].mean()\n",
    "  df['col2_to_std_col1'] = df['col2'] / df['col2'].std()\n",
    "  df['col3_to_std_col1'] = df['col3'] / df['col3'].std()\n",
    "  return df\n",
    "\n",
    "df.groupBy('col1').apply(transformMean).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert a column in DataFrame into a python list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+----+----+----+\n",
       "col1|col2|col3|\n",
       "+----+----+----+\n",
       "   a| 2.0| 3.0|\n",
       "   a| 5.0| 6.0|\n",
       "   b| 8.0| 9.0|\n",
       "   b| 1.0| 3.0|\n",
       "+----+----+----+\n",
       "\n",
       "<span class=\"ansired\">Out[</span><span class=\"ansired\">5</span><span class=\"ansired\">]: </span>[2.0, 5.0, 8.0, 1.0]\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfSchema = T.StructType([\n",
    "  T.StructField('col1', T.StringType(), True),\n",
    "  T.StructField('col2', T.FloatType(), True),\n",
    "  T.StructField('col3', T.FloatType(), True)\n",
    "])\n",
    "\n",
    "df = spark.createDataFrame(data=[('a', 2.0, 3.0), ('a', 5.0, 6.0), ('b', 8.0, 9.0), ('b', 1.0, 3.0)], schema=dfSchema)\n",
    "df.show()\n",
    "\n",
    "column_as_list  = df.select('col2').rdd.flatMap(lambda x: x).collect()\n",
    "column_as_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the no. of missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def countNullNan(colName):\n",
    "  return F.count(F.when((F.isnull(colName) | F.isnan(colName)), 'missingValue')).alias(colName)\n",
    "\n",
    "df.select(*[countNullNan(colName) for colName in df.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "name": "pySparkNotes",
  "notebookId": 2049034754195359,
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
